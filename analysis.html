<!DOCTYPE html>
<html lang="en">

<head>

	<title>Analysis | TBD</title>
	
	<meta charset="utf-8">
	<meta name="viewpoint" content="width=device-width, initial-scale=1">
	<link rel="icon" href="./images/uoft.png">
	
	<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/css/bootstrap.min.css" 
		integrity="sha384-/Y6pD6FV/Vv2HJnA6t+vslU6fwYXjCFtcEpHbNJ0lyAFsXTsjBbfaDjzALeQsN6M" crossorigin="anonymous">
	<link rel="stylesheet" type="text/css" href="ecosystem.css">
	<link rel="stylesheet" type="text/css" href="tbd.css">
	<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">

	<script src="https://www.w3schools.com/lib/w3.js"></script>
	<script src="https://use.fontawesome.com/fd789ca0f7.js"></script>

</head>

<body>

	<div w3-include-html="./components/tbd-titlebar.html"></div>

	<main id="content" role="main" class="doc">
		<div class="container">
		  <br><br>
		  <h2>Analysis</h2>
		  <br>
		
			<div class="container">
			
				<div class="section" id="methodology">
					<div>
						<h3>Methodology</h3>
					</div>
					
					<div>
						We collect profile data using nvprof. A typical example looks like this:
						<br><br>
						<code>/usr/local/cuda/bin/nvprof --profile-from-start off --export-profile profiler_output.nvvp -f --print-summary python program.py --program-args</code>
						<br><br>
						Likewise, we also collect floating-point utilization data:
						<br><br>
						<code>/usr/local/cuda/bin/nvprof --profile-from-start off --export-profile profiler_output_fp32.nvvp -f --print-summary --metrics single_precision_fu_utilization python program.py --program-args </code>
					</div>
					<br><br>
					
					<div class="container">
						<div class="section" id="gpu-occupancy">
							<div>
								<h4>Delayed and Focused Profiling</h4>
							</div>
							
							<div>
								Since neural network libraries may include tuning
								operations at the start of training, to obtain a representative sample of the training process, we wait 
								multiple iterations before turning on profiling.
								With python, we use the numba library to control
								when profiling samples are taken.
								
								<br><br>
								<code>
								import numba.cuda as cuda
								</code>
								
								<br><br> 
								We call <code>cuda.profile_start()</code> to begin the profiling, and
								<code>cuda.profile_stop()</code> to end
								profiling. Since generated profile files can 
								become large and each training iteration follows the same computation
								logic, the profiling period is usually chosen
								to be only a small number of iterations. Moreover,
								we carefully choose a period that includes
								only training computations, without validation. After cuda.profile_stop() is hit,
								the training process can be safely killed with Ctrl+c. The .nvvp file
								exported by the <code>--export-profile</code> option can be viewed by NVidia Visual Profiler
								for further analysis.
							</div>
						</div>
						<br><br>
						
						<div class="section" id="throughput">
							<div>
								<h4>Throughput</h4>
							</div>
							
							<div>
								Throughput measures the number of training cases or
								samples, where applicable, that are processed per 
								second during training. Most benchmarks already
								have throughput statistics output in training logs without additional
								work. For Deep Speech 2, which has no training throughput numbers
								logged directly, we measure the sum of all data samples between two
								time stamps in the training logs. As the lengths of the data samples vary
								a lot, we use the total length of data samples instead of a simple count to 
								measure training throughput with Deep Speech 2.
							
								<br>
								<br>
								<img class="col-md-6 col-xs-12 margin-bottom-20 max-width-100 width-500" 
									src="./images/sigmetrics18/throughput_resnet.png">
								<img class="col-md-6 col-xs-12 margin-bottom-20 max-width-100 width-500"
									src="./images/sigmetrics18/throughput_DS2.png">
							</div>
						</div>
						<br><br>
						
						<div class="section" id="gpu-occupancy">
							<div>
								<h4>Compute Utilization</h4>
								<div class="margin-bottom-20">
								</div>
							</div>
							
							<div>
								GPU compute utilization measures the relative amount of time 
								that the GPU spends actively running kernels. NVidia Visual Profiler provides this
								information directly, but the profiling overhead time should be excluded from that number.
								
								<br>
								<br>
								<img class="col-md-6 col-xs-12 margin-bottom-20 max-width-100 width-500" 
									src="./images/sigmetrics18/occupation_transformer.png">
								<img class="col-md-6 col-xs-12 margin-bottom-20 max-width-100 width-500" 
									src="./images/sigmetrics18/occupation_wgan.png">
							</div>
						</div>
						<br><br>
						
						<div class="section" id="fp-utilization">
							<div>
								<h4>Floating-Point Utilization</h4>
							</div>
							
							<div>
								GPU floating point utilization quantifies how busy
								the GPU's floating-point compute units are during
								training. This is informative since floating-point 
								arithmetic comprises the majority of computation
								in all benchmarks. This is reported by the
								profiler when run with the <code>--metrics single_precision_fu_utilization</code>
								option as above.
								
								The profiler generates the FP32 utilization for each individual kernel. We calculate a weighted sum
								over all kernels for the overall FP32 utilization of the training. We can also
								determine which kernels are long but with low utilization. Such kernels are good targets for optimization.
								<br>
								<br>
								<img class="col-md-6 col-xs-12 margin-bottom-20 max-width-100 width-500" 
									src="./images/sigmetrics18/utilization_resnet.png">
								<img class="col-md-6 col-xs-12 margin-bottom-20 max-width-100 width-500" 
									src="./images/sigmetrics18/utilization_a3c.png">
								
							</div>
						</div>
						<br><br>

						<div class="section" id="sensitivity">
							<div>
								<h4>Hardware Sensitivity</h4>
							</div>
							
							<div>
								<p>We studied how the performance of DNN training is affected by the hardware used. We used TitanXp for comparison against Quadro P4000. Detailed hardware specifications of these two types GPU are shown following:</p>
								<br>
								<table style="width:100%">
								  <tr>
									<th></th>
									<th># of Multi-processors</th> 
									<th>Core count</th>
									<th>Max Clock Rate (MHz)</th>
									<th style="padding:0 5px 0 0px;">Memory Size (GB)</th>
									<th style="padding:0 5px 0 0px;">LLC Size (MB)</th>
									<th style="padding:0 5px 0 0px;">Memory Bus Type</th>
									<th style="padding:0 5px 0 0px;">Memory BW (GB/s)</th>
									<th>Bus Interface</th>
									<th>Memory Speed (MHz)</th>
								  </tr>
								  <tr>
									<td style="padding:0 15px 0 0px;">TitanXp</td>
									<td>30</td> 
									<td>3840</td>
									<td>1582</td>
									<td>12</td>
									<td>3</td>
									<td>GDDR5X</td>
									<td>547.6</td>
									<td>PCIe 3.0</td>
									<td>5705</td>
								  </tr>
								  <tr>
									<td>P4000</td>
									<td>14</td> 
									<td>1792</td>
									<td>1480</td>
									<td>8</td>
									<td>2</td>
									<td>GDDR5</td>
									<td>243</td>
									<td>PCIe 3.0</td>
									<td>3802</td>
								  </tr>
								</table>

								<br>
								We compare the training throughput, GPU utilization and FP32 utilization. The results show that although the more advanced GPU (Titan Xp) delivers better training throughput, its compute resources are still under-utilized.
								
								<br>
								<br>
								<img class="col-md-6 col-xs-12 margin-bottom-20 max-width-100 width-340" 
									src="./images/sigmetrics18/throughput_comparison_TF-1.png">
								<img class="col-md-6 col-xs-12 margin-bottom-20 max-width-100 width-340" 
									src="./images/sigmetrics18/occupation_comparison_TF-1.png">
								<img class="col-md-6 col-xs-12 margin-bottom-20 max-width-100 width-340" 
									src="./images/sigmetrics18/utilization_comparison_TF-1.png">
								
							</div>
						</div>
						<br><br>

						<div class="section" id="distributed">
							<div>
								<h4>Distributed Training</h4>
							</div>
							
							<div>
								Training large DNNs can be done faster when multiple GPUs and/or multiple
								machines are used. This is usually achieved by using data parallelism, where
								mini-batches are split among individual GPUs and the results are then merged.
								We studied how the scalability is affected by the network bandwidth. We tested
								the training of ResNet-50 on MXNet on both multi-GPU and multi-machine environments.
								Our prilimary results show that the bandwidth of 1 Gb/s ethernet will greatly lower the
								overall training performance, and that the bandwidth of 100 Gb/s infiniband is sufficient for
								delivering good scalability in a multi-machine environment.
								
								
								<br>
								<br>
								<img class="col-md-6 col-xs-12 margin-bottom-20 max-width-100 width-500" 
									src="./images/sigmetrics18/multi_machine.jpg">
								
								<br>
								The first level of the x-axis shows the per-machine mini-batch size, and
								the second level of the x-axis shows the number of machines. 
								In the case where multiple GPUs located in the same machine, all GPUs are connected with the host
								through a 6 GB/s PCIe bus. It is able to deliver high scalability, but slightly lower throughput.
								<br>
								<br>
								<img class="col-md-6 col-xs-12 margin-bottom-20 max-width-100 width-500" 
									src="./images/sigmetrics18/multi_GPU.jpg">
							</div>
						</div>
					</div>
					
				</div>
				<br><br>
				
			</div>
		</div>
        <br/><br/>
	</main>

	<script>w3.includeHTML();</script>

	<script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" 
		integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" 
		crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.11.0/umd/popper.min.js" 
		integrity="sha384-b/U6ypiBEHpOf/4+1nzFpr53nxSS+GLCkfwBdFNTxtclqqenISfwAzpKaMNFNmj4" 
		crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/js/bootstrap.min.js" 
		integrity="sha384-h0AbiXch4ZDo7tp9hKZ4TsHbi047NrKGLO3SEJAg45jXxnGIfYzk4Si90RDIqNm1" 
		crossorigin="anonymous"></script>

</body>
</html>
